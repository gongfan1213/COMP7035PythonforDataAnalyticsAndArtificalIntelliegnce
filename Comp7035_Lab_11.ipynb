{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebe94592-8589-440e-9bb8-8bae5376ec03",
   "metadata": {},
   "source": [
    "# Lab Demo COMP7035 Week 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4d0970-2b4b-484e-a961-93d6e788b201",
   "metadata": {},
   "source": [
    "## Lab Demo COMP7035 Week 10\n",
    "### Be familiar with Keras for creating deep learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afe2d2a-0524-4674-91f0-d91842dc515d",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f49526-9692-4c0b-b61f-68e52f811a37",
   "metadata": {},
   "source": [
    "## Problem 1: Defining a CNN model with Keras (1)\n",
    "#### Using Sequential API to define a CNN model. The CNN model follows the architecture below and outputs the model summary. \n",
    "![avatar](cnn1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b0b703-23b6-4952-ac43-850b498a91ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 252, 252, 32)      832       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 126, 126, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 126, 126, 1)       33        \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 15876)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                158770    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 159635 (623.57 KB)\n",
      "Trainable params: 159635 (623.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Reshape\n",
    "import numpy as np\n",
    "\n",
    "n_filter1 = 32\n",
    "n_filter2 = 1\n",
    "filter_size1 = 5\n",
    "filter_size2 = 1\n",
    "\n",
    "# Write your codes to define the CNN model\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first convolutional layer\n",
    "model.add(Conv2D(n_filter1, filter_size1, activation='relu', input_shape=(256, 256, 1)))\n",
    "\n",
    "# Add the max pooling layer\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add the second convolutional layer\n",
    "model.add(Conv2D(n_filter2, filter_size2, activation='relu'))\n",
    "\n",
    "# Add the flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add the dense layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Test the CNN model\n",
    "x = np.random.randn(1, 256, 256)\n",
    "y = model(x)\n",
    "\n",
    "# Print the model summary again\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aaa96d-d1d3-4d1b-855f-f61ab375868c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Problem 2: Defining a CNN model with Keras (2)\n",
    "#### Using the Functional API to define another CNN model. The CNN model follows the architecture below and outputs the model summary.\n",
    "![avatar](cnn2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b83a03-eff0-4bba-8b2b-772f40a19468",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 256, 256, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 252, 252, 8)       208       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 126, 126, 8)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 110, 110, 8)       18504     \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 96800)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                968010    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 986722 (3.76 MB)\n",
      "Trainable params: 986722 (3.76 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Reshape\n",
    "import numpy as np\n",
    "\n",
    "n_filter1 = 8\n",
    "n_filter2 = 8\n",
    "filter_size1 = 5\n",
    "filter_size2 = 17\n",
    "\n",
    "x = np.random.randn(1, 256, 256)\n",
    "\n",
    "# Write your codes to define your CNN model\n",
    "\n",
    "# Define the input tensor\n",
    "inputs = keras.Input(shape=(256, 256, 1))\n",
    "\n",
    "# Apply the first convolutional layer\n",
    "conv1 = Conv2D(n_filter1, filter_size1, activation='relu')(inputs)\n",
    "\n",
    "# Apply the max pooling layer\n",
    "pool1 = MaxPool2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "# Apply the second convolutional layer\n",
    "conv2 = Conv2D(n_filter2, filter_size2, activation='relu')(pool1)\n",
    "\n",
    "# Flatten the output\n",
    "flatten = Flatten()(conv2)\n",
    "\n",
    "# Apply the dense layer\n",
    "dense = Dense(10, activation='softmax')(flatten)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=inputs, outputs=dense)\n",
    "y = model(x)\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e3920e-0510-4884-95f1-4d2b223d9e26",
   "metadata": {},
   "source": [
    "## Problem 3: Loss Functions (Mean Squared Error vs. Mean Absolute Error)\n",
    "#### Given y_true and y_pred, calculating the MSE and MAE values  \n",
    "#### Task 3.1 Measure the MSE value \n",
    "#### Task 3.2 Measure the MAE value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d13916-b71f-4ce6-bf31-60d1c84beff1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE value is 0.8725000023841858\n",
      "The MAE value is 0.925000011920929\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.losses import MeanAbsoluteError, MeanSquaredError\n",
    "mse = MeanSquaredError()\n",
    "mae = MeanAbsoluteError()\n",
    "\n",
    "y_true = np.array([[0., 0.3], [0., 1.]])\n",
    "y_pred = np.array([[1., 1.], [1., 0.]])\n",
    "\n",
    "# Mean Squared Error (MSE) \n",
    "# Task 3.1 Write your codes to measure the MSE value\n",
    "\n",
    "# Measure the MSE value\n",
    "z_mse = mse(y_true, y_pred)\n",
    "print(\"The MSE value is {}\".format(z_mse.numpy()))\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "# Task 3.2 Write your codes to measure the MAE value\n",
    "z_mae = mae(y_true, y_pred)\n",
    "print(\"The MAE value is {}\".format(z_mae.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ec248f-262c-48c7-abfb-bab9e25e71f6",
   "metadata": {},
   "source": [
    "## Problem 4: Loss Functions (Categorical Cross-Entropy)\n",
    "#### Given y_true and y_pred, calculating the Categorical Cross-Entropy value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cff5ec6-b299-43c4-a18d-8ec2686f7336",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Categorical Cross-Entropy value is 1.1769392490386963\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy, BinaryCrossentropy\n",
    "\n",
    "y_true = np.array([[0, 1, 0], [0, 0, 1]])\n",
    "y_pred = np.array([[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n",
    "\n",
    "# Categorical Cross-entropy\n",
    "# Write your codes to measure the categorical cross-entropy\n",
    "cce = CategoricalCrossentropy()\n",
    "z = cce(y_true, y_pred)\n",
    "\n",
    "print(\"The Categorical Cross-Entropy value is {}\".format(z.numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f389b2-8118-47d6-ae2c-14382f900514",
   "metadata": {},
   "source": [
    "## Problem 5: Loss Functions (Sparse Cross-Entropy)\n",
    "#### Given y_true and y_pred, calculating the Sparse Cross-Entropy value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2914ad4-1609-448f-af60-23d602502404",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Sparse Cross-Entropy value is 1.1769392490386963\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "y_true = np.array([1, 2])\n",
    "y_pred = np.array([[0.05, 0.95, 0], [0.1, 0.8, 0.1]])\n",
    "\n",
    "# Sparse Cross-entropy\n",
    "## Write your codes to measure the Sparse Categorical-entropy\n",
    "\n",
    "\n",
    "# Sparse Cross-entropy\n",
    "z = SparseCategoricalCrossentropy()(y_true, y_pred)\n",
    "\n",
    "print(\"The Sparse Cross-Entropy value is {}\".format(z.numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a0a9e2-2515-4ebc-9df9-bfcafc45c66b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem 6: Loss Functions (Binary Cross-Entropy)\n",
    "#### Given y_true and y_pred, calculating the Binary Cross-Entropy value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa3abf2-3263-46e4-8b7d-3b84200b2cdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Binary Cross-Entropy value is 4.001645565032959\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "y_true = np.array([0, 1, 0, 0])\n",
    "y_pred = np.array([-18.6, 0.51, 2.94, -12.8])\n",
    "\n",
    "# Binary Cross-entropy\n",
    "# Write your codes to measure the Binary Cross-entropy\n",
    "\n",
    "\n",
    "# Binary Cross-entropy\n",
    "z = BinaryCrossentropy()(y_true, y_pred)\n",
    "\n",
    "print(\"The Binary Cross-Entropy value is {}\".format(z.numpy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f9875a-ca02-4909-b90f-33a06b1667ba",
   "metadata": {},
   "source": [
    "## Problem 7: Optimizer and Evaluation\n",
    "#### Task 7.1 set up the deep learning model based on the given DNN structure.\n",
    "###### Input(28x28x1) -> Conv2D(32, kernel_size=3) -> MaxPooling2D(2) -> Conv2D(64, kernel_size=3) -> MaxPooling2D(2) -> Dropout(0.5) -> Dense(10, 'softmax')\n",
    "##### Task 7.1 using Adam optimizer and fitting the CNN model \n",
    "##### Task 7.2 evaluating the performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2cadff9-9cfa-41cb-b430-920594bc5030",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Conv2D, MaxPool2D, Flatten, Dropout, MaxPooling2D\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, MaxPooling2D\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "# Write your codes to set up Adam optimizer and fit the CNN model\n",
    "# Compile the model with Adam optimizer\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the CNN model\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the performance on the test data\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Print the test loss and accuracy\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c798a38-c5c1-4e9a-a537-b1c9cf07aa3a",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c66b102-b3c9-4f5d-9ab4-71c924b0d169",
   "metadata": {},
   "source": [
    "#### Defining your customized CNN or DNN model for pattern classification on the Fashion MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c91e91-5298-4623-bdd6-2c1cd8a08b8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# baseline cnn model for fashion mnist\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9e60ea-ef3a-457a-b999-74fbb9c07148",
   "metadata": {},
   "source": [
    "##### Loading the Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b675334-eae1-4f7c-8939-540522e384e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "    # load dataset\n",
    "    (trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
    "    # reshape dataset to have a single channel\n",
    "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "    testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "    # one hot encode target values\n",
    "    trainY = to_categorical(trainY)\n",
    "    testY = to_categorical(testY)\n",
    "    \n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aee965-08be-4e0a-b912-9d1e011714ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    # return normalized images\n",
    "\n",
    "    return train_norm, test_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cf3f06-0605-489f-a269-9fee0a2b6476",
   "metadata": {},
   "source": [
    "##### Defining your customised CNN or DNN model as shown in classes using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "941e1575-286f-4af8-835b-d829cb5198c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define CNN model\n",
    "def define_model():\n",
    "    model = Sequential()\n",
    "    # Write your codes to define your model\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc5fee12-b6a6-4f0d-bf44-07d2ff7e2436",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate a model using k-fold cross-validation\n",
    "def evaluate_model(dataX, dataY, n_folds=5):\n",
    "    scores, histories = list(), list()\n",
    "    # prepare cross validation\n",
    "    kfold = KFold(n_folds, shuffle=True, random_state=1)\n",
    "    \n",
    "    # enumerate splits\n",
    "    for train_ix, test_ix in kfold.split(dataX):\n",
    "        # define model\n",
    "        model = define_model()\n",
    "        # select rows for train and test\n",
    "        trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
    "        # fit model\n",
    "        history = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
    "        # evaluate model\n",
    "        \n",
    "    _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "    # append scores\n",
    "    scores.append(acc)\n",
    "    histories.append(history)\n",
    "    \n",
    "    return scores, histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fff1fede-c61d-43c3-936c-7d3930506b24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(histories):\n",
    "    for i in range(len(histories)):\n",
    "        # plot loss\n",
    "        pyplot.subplot(211)\n",
    "        pyplot.title('Cross Entropy Loss')\n",
    "        pyplot.plot(histories[i].history['loss'], color='blue', label='train')\n",
    "        pyplot.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
    "        # plot accuracy\n",
    "        pyplot.subplot(212)\n",
    "        pyplot.title('Classification Accuracy')\n",
    "        pyplot.plot(histories[i].history['accuracy'], color='blue', label='train')\n",
    "        pyplot.plot(histories[i].history['val_accuracy'], color='orange', label='test')\n",
    "        pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f20ee057-00ac-45e3-ba5a-ebe0be4c8ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# summarize model performance\n",
    "def summarize_performance(scores):\n",
    "    # print summary\n",
    "    print('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n",
    "    # box and whisker plots of results\n",
    "    pyplot.boxplot(scores)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6538ffc8-ebe1-4b9a-9e57-66f44f0c793c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels(trainX, testX)\n",
    "    # evaluate model\n",
    "    scores, histories = evaluate_model(trainX, trainY)\n",
    "    # learning curves\n",
    "    summarize_diagnostics(histories)\n",
    "    # summarize estimated performance\n",
    "    summarize_performance(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b8527-818b-449e-8517-b098fd5d22c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e172c9-11d7-4750-8f0d-21fed232368d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
